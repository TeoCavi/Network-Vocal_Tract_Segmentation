{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import med_dataloader as mdl\r\n",
    "import tensorflow as tf\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "num_classes = 7"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "os.getcwd()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\matte\\\\Desktop\\\\Network-Vocal_Tract_Segmentation'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generazione Dataset\r\n",
    "## "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "mdl.generate_dataset(data_dir= os.path.join(os.getcwd(), \"Dataset_Prova\"),\r\n",
    "                        imgA_label=\"Images\",\r\n",
    "                        imgB_label=\"Segmentation_checked\",\r\n",
    "                        input_size=256,\r\n",
    "                        is_B_categorical=True,\r\n",
    "                        num_classes=num_classes,\r\n",
    "                        norm_boundsA=[0,255], #normalizza tra 0 e 1; bisogna mettere lower_bound,upper_bound dell'immagine corrente!!! (non i limiti che si vogliono raggiungere)\r\n",
    "                        norm_boundsB=None,\r\n",
    "                        )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Caching decoded images in c:\\Users\\matte\\Desktop\\Network-Vocal_Tract_Segmentation\\Dataset_Prova_TF\\Images.cache...\n",
      "460/460\n",
      "Cached decoded images in c:\\Users\\matte\\Desktop\\Network-Vocal_Tract_Segmentation\\Dataset_Prova_TF\\Images.cache.\n",
      "Caching decoded images in c:\\Users\\matte\\Desktop\\Network-Vocal_Tract_Segmentation\\Dataset_Prova_TF\\Segmentation_checked.cache...\n",
      "460/460\n",
      "Cached decoded images in c:\\Users\\matte\\Desktop\\Network-Vocal_Tract_Segmentation\\Dataset_Prova_TF\\Segmentation_checked.cache.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_ds, validation_ds, test_ds = mdl.get_dataset(data_dir = os.path.join(os.getcwd(), \"Dataset_Prova_TF\"),\r\n",
    "                                                    percentages = [0.8, 0.1, 0.1],\r\n",
    "                                                    batch_size = 4,\r\n",
    "                                                    train_augmentation = False,\r\n",
    "                                                    random_crop_size = None,\r\n",
    "                                                    random_rotate = False,\r\n",
    "                                                    random_flip = False,\r\n",
    "                                                    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Controllo massimo e minimo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "max = 0\r\n",
    "min = 255\r\n",
    "for batch in train_ds.take(93): #meno hc\r\n",
    "    volume_batch, label_batch = batch\r\n",
    "    for i in range(4): #meno hc\r\n",
    "        max_start = np.max(volume_batch[i,:,:])\r\n",
    "        min_start = np.min(volume_batch[i,:,:])\r\n",
    "        if max_start > max:\r\n",
    "            max = max_start\r\n",
    "        if min_start < min:\r\n",
    "            min = min_start\r\n",
    "\r\n",
    "#print(np.shape(volume_batch))\r\n",
    "print(max, min)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.0 0.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plottaggio dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plottaggio completo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "print(train_ds)\r\n",
    "\r\n",
    "batch_n = 0\r\n",
    "\r\n",
    "for batch in train_ds.take(93):  #rendi meno hard code \r\n",
    "    volume_batch, label_batch = batch\r\n",
    "    #fig = plt.figure(figsize = [23, 7])\r\n",
    "    print(\"Batch nÂ°: \", batch_n)\r\n",
    "    batch_n = batch_n + 1\r\n",
    "\r\n",
    "    for volume, label in zip(volume_batch, label_batch):\r\n",
    "        fig = plt.figure(figsize = [23, 7]) #creo ogni ciclo la figura bianca\r\n",
    "        plt.subplot(1, num_classes + 1, 1) #creo le colonne e le righe\r\n",
    "        plt.imshow(volume[:,:,0], cmap=\"gray\") #ploto l'immagine\r\n",
    "\r\n",
    "        for i in range(num_classes):\r\n",
    "            \r\n",
    "            plt.subplot(1, num_classes + 1, i+2) #muovo l'indice di colonna per plottare le varie classi \r\n",
    "            plt.imshow(label[:,:,i], cmap=\"plasma\", alpha=0.5) #plotto le classi \r\n",
    "    plt.show(fig) #stampo il tutto"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualizzazione classi in forma matriciale"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "batch = train_ds.take(1)\r\n",
    "\r\n",
    "for volume , label in zip(volume_batch, label_batch):\r\n",
    "    plt.imshow(label[:,:,2])\r\n",
    "    plt.colorbar()\r\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('Virtual_Env': venv)"
  },
  "interpreter": {
   "hash": "a3ef9f1017b2df126a2f55c5b9f1431007f60732979d986d4cc140fd3016b06f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}